{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65580f3-5247-4e6a-aa54-3be26dd2cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the two main libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup  # to process html\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4f7405-25fd-45af-abd2-8033edeed787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:33<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "#get all the links of the articles\n",
    "\n",
    "daily_mail_links = []\n",
    "for page in tqdm(range(1,21)):\n",
    "\n",
    "    url = 'https://www.dailymail.co.uk/news/russia-ukraine-conflict/index.html?page='+str(page)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    links = soup.find_all('h2',{'linkro-darkred'})\n",
    "    \n",
    "    for link in links:\n",
    "        daily_mail_links.append(link.find('a')['href'].strip())\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "269a4dc4-5091-4940-9a2c-36dc259a1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"daily_mail_links.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(daily_mail_links, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b8bb9178-b6cf-4e49-a655-b6f7f3643f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "DailyArticles = pd.DataFrame({'title': pd.Series([], dtype='string'),\n",
    "                             'author': pd.Series([], dtype='string'),\n",
    "                             'date': pd.Series([], dtype='string'),\n",
    "                             'text': pd.Series([], dtype='string'),\n",
    "                             })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fd41a588-1bbc-4529-87bc-531d4e4cd94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [31:27<00:00,  1.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for i,link in enumerate(tqdm(daily_mail_links)):\n",
    "    \n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    \n",
    "    #get title\n",
    "    title = soup.find_all(\"div\", {\"class\": \"article-text wide heading-tag-switch\"})\n",
    "    \n",
    "    if len(title) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        title = title[0].find('h2').get_text()\n",
    "    \n",
    "    #get author\n",
    "    authors = soup.find_all('a', {'class': 'author'})\n",
    "    art_authors = authors[0].get_text()\n",
    "    for i in range(1,len(authors)):\n",
    "        art_authors = art_authors +\", \" + authors[1].get_text()\n",
    "        \n",
    "        \n",
    "    #get date\n",
    "    date = soup.find_all('span', {'class': 'article-timestamp article-timestamp-published'})\n",
    "    if len(date) > 0:\n",
    "        date = date[0].find('time').get_text().split(',')[1].strip()\n",
    "    else:\n",
    "        date = soup.find_all('span', {'class': 'article-timestamp article-timestamp-updated'})[0].find('time').get_text().split(',')[1].strip()\n",
    "        \n",
    "    date = pd.to_datetime(date).strftime('%d/%m/%y')\n",
    "    \n",
    "    #get text\n",
    "    text = ''\n",
    "    for p in soup.find_all('p',{'class' : 'mol-para-with-font'}):\n",
    "        text += p.text\n",
    "    \n",
    "    entry = {'link': link,'title': title, 'author': art_authors,'date': date,'text':text}\n",
    "    DailyArticles = pd.concat([DailyArticles, pd.DataFrame(entry, index=[0])], ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27618aa1-35c3-4f9f-b4fb-90746e24f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the user agent in order to get the json fil with the comments\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.2 Safari/605.1.15'\n",
    "    }  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "966a54e3-61f8-4d81-b5be-4d930c6db561",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1277/1277 [05:54<00:00,  3.60it/s]\n"
     ]
    }
   ],
   "source": [
    "DailyArticles[\"comments\"] = 0\n",
    "articleNumber = []\n",
    "\n",
    "for i, link in enumerate(tqdm(DailyArticles[\"link\"])):\n",
    "    comments = []\n",
    "    articleNumber = link.split('article-')[1].split('/')[0]\n",
    "    data = requests.get(\n",
    "        'https://www.dailymail.co.uk/reader-comments/p/asset/readcomments/'\n",
    "        + str(articleNumber)\n",
    "        + '?max=1000&sort=voteRating&order=desc',headers = headers)\n",
    "\n",
    "    data = json.loads(data.text)\n",
    "\n",
    "    for comment in data[\"payload\"]['page']:\n",
    "        comments.append(comment[\"message\"])\n",
    "\n",
    "    DailyArticles[\"comments\"][i] = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ac7eeb2-dbed-409d-8f77-e91c6179f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "DailyArticles.to_parquet(\"DailyMail.parquet.snappy\", engine=\"fastparquet\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baa5556-5ded-4a44-8276-45f78a532b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
