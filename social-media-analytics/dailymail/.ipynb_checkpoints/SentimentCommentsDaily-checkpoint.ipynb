{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Social Media Analytics\n",
    "### Introduction to Text Mining\n",
    "## Sentiment Analysis\n",
    "(c) Nuno Antonio 2019-2022 v1.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import csv\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_parquet(\"DailyMailComments.parquet.snappy\", engine=\"fastparquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>Russians don't appear to understand that peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>The Russians dont like it up em do they? They ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>well, russians wanted war.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>wait till the war gets to Moscow  ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>Russians hate Britain\\nAnd what they particula...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.dailymail.co.uk/news/article-12155...   \n",
       "1  https://www.dailymail.co.uk/news/article-12155...   \n",
       "2  https://www.dailymail.co.uk/news/article-12155...   \n",
       "3  https://www.dailymail.co.uk/news/article-12155...   \n",
       "4  https://www.dailymail.co.uk/news/article-12155...   \n",
       "\n",
       "                                             comment  \n",
       "0  Russians don't appear to understand that peopl...  \n",
       "1  The Russians dont like it up em do they? They ...  \n",
       "2                         well, russians wanted war.  \n",
       "3             wait till the war gets to Moscow  ....  \n",
       "4  Russians hate Britain\\nAnd what they particula...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12029 entries, 0 to 12028\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   link     12029 non-null  object\n",
      " 1   comment  12029 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 188.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "def textPreProcess(\n",
    "    rawText,\n",
    "    removeHTML=True,\n",
    "    charsToRemove=r\"\\?|\\.|\\!|\\;|\\.|\\\"|\\,|\\(|\\)|\\&|\\:|\\-\",\n",
    "    removeNumbers=True,\n",
    "    removeLineBreaks=False,\n",
    "    specialCharsToRemove=r\"[^\\x00-\\xfd]\",\n",
    "    convertToLower=True,\n",
    "    removeConsecutiveSpaces=True,\n",
    "):\n",
    "    if type(rawText) != str:\n",
    "        return rawText\n",
    "    procText = rawText\n",
    "\n",
    "    # Remove HTML\n",
    "    if removeHTML:\n",
    "        procText = BeautifulSoup(procText, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove punctuation and other special characters\n",
    "    if len(charsToRemove) > 0:\n",
    "        procText = re.sub(charsToRemove, \" \", procText)\n",
    "\n",
    "    # Remove numbers\n",
    "    if removeNumbers:\n",
    "        procText = re.sub(r\"\\d+\", \" \", procText)\n",
    "\n",
    "    # Remove line breaks\n",
    "    if removeLineBreaks:\n",
    "        procText = procText.replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
    "\n",
    "    # Remove special characters\n",
    "    if len(specialCharsToRemove) > 0:\n",
    "        procText = re.sub(specialCharsToRemove, \" \", procText)\n",
    "\n",
    "    # Normalize to lower case\n",
    "    if convertToLower:\n",
    "        procText = procText.lower()\n",
    "\n",
    "    # Replace multiple consecutive spaces with just one space\n",
    "    if removeConsecutiveSpaces:\n",
    "        procText = re.sub(\" +\", \" \", procText)\n",
    "\n",
    "    return procText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "def tokenize_words(words):\n",
    "    if (type(words) != str) or (word_tokenize(words) == \"\"):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return word_tokenize(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create text from words\n",
    "def recreateText(words):\n",
    "    if type(words) == list:\n",
    "        temp_str = (\" \").join(words)\n",
    "        return temp_str\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to break texts into sentences\n",
    "def tokenize_sentences(texts):\n",
    "    s_token = sent_tokenize(texts)\n",
    "    return s_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove stop words\n",
    "def removeStopWords(t, stop_words):\n",
    "    if type(t) == list:\n",
    "        return [w for w in t if not w in stop_words]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because a review can express multiple opinions, let's analyze opinions by sentence\n",
    "\n",
    "# Break reviews' into a list of lists sentencesc\n",
    "listOfSentences = ds.comment.apply(tokenize_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosk/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with only the description\n",
    "processedReviews = pd.DataFrame(\n",
    "    data=ds.comment.apply(\n",
    "        textPreProcess, charsToRemove=\"\", removeLineBreaks=False, removeNumbers=False\n",
    "    ).values,\n",
    "    index=ds.index,\n",
    "    columns=[\"PreProcessedText\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'well, russians wanted war.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first review\n",
    "ds.comment[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well, russians wanted war.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentences of first review\n",
    "listOfSentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for sentences\n",
    "sentences = pd.DataFrame(\n",
    "    data=[item for elem in listOfSentences for item in elem], columns=[\"BaseText\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the review ID\n",
    "sentencesPerReview = []\n",
    "for elem in listOfSentences:\n",
    "    sentencesPerReview.append(len(elem))\n",
    "sentences[\"link\"] = np.repeat(ds[\"link\"].values, sentencesPerReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "sentences[\"PreProcessedText\"] = sentences[\"BaseText\"].apply(textPreProcess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words\n",
    "sentences[\"Words\"] = sentences[\"PreProcessedText\"].apply(tokenize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentences[\"WordsCleaned\"] = sentences[\"Words\"].apply(\n",
    "    removeStopWords, stop_words=stop_words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate sentence without stopwords\n",
    "sentences[\"ProcessedText\"] = sentences[\"WordsCleaned\"].apply(recreateText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment analysis object\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "russians n't appear understand people tend retaliate attacked {'neg': 0.3, 'neu': 0.7, 'pos': 0.0, 'compound': -0.4588}\n"
     ]
    }
   ],
   "source": [
    "# To test, let's evaluate first sentence of first review\n",
    "# Scales:\n",
    "#   compound: -1:most extreme negative, 1:most extreme positive\n",
    "#     positive: compound >=0.05\n",
    "#     neutral: -0.05<compound<0.05\n",
    "#     negative: compound <= -0.05\n",
    "#   pos, neu, neg: proportion of text that are positive, neutral or negative\n",
    "score = analyser.polarity_scores(sentences[\"ProcessedText\"][0])\n",
    "print(sentences[\"ProcessedText\"][0], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nopen_file = open(\"comments-dailymail.pkl\", \"rb\")\\nsentences = pickle.load(open_file)\\nopen_file.close()\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing sentences sentiment requires around 40 minutes, using this file we have the saved results.\n",
    "\"\"\"\n",
    "open_file = open(\"sentimentCommentsdaily.pkl\", \"rb\")\n",
    "sentences = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22386/22386 [50:26<00:00,  7.40it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Process sentiment for all sentences\n",
    "all_scores = []\n",
    "for t in tqdm(sentences[\"ProcessedText\"]):\n",
    "    try:\n",
    "        score = analyser.polarity_scores(t)\n",
    "        all_scores.append(score)\n",
    "    except:\n",
    "        all_scores.append(dict({\"neg\": 0.0, \"neu\": 0.0, \"pos\": 0.0, \"compound\": 0.0}))\n",
    "sentences[\"Sentiment\"] = [c[\"compound\"] for c in all_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"sentimentCommentsdaily.pkl\"\n",
    "\n",
    "open_file = open(file_name, \"wb\")\n",
    "pickle.dump(sentences, open_file)\n",
    "open_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute review's sentiment as the mean sentiment from its sentences\n",
    "meanByReview = sentences.groupby(\"link\")[\"Sentiment\"].mean()\n",
    "\n",
    "# Consider sentences with no result as neutral (0)\n",
    "meanByReview = meanByReview.fillna(0)\n",
    "\n",
    "# Add column Sentiment to reviews Dataframe\n",
    "ds[\"Sentiment\"] = meanByReview[ds[\"link\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a qualitative evaluation to the review\n",
    "bins = pd.IntervalIndex.from_tuples(\n",
    "    [(-1.1, -0.05), (-0.05, 0.05), (0.05, 1)], closed=\"right\"\n",
    ")\n",
    "x = pd.cut(ds[\"Sentiment\"].to_list(), bins)\n",
    "x.categories = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "ds[\"Polarity\"] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>comment</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>Russians don't appear to understand that peopl...</td>\n",
       "      <td>-0.183453</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>The Russians dont like it up em do they? They ...</td>\n",
       "      <td>-0.183453</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>well, russians wanted war.</td>\n",
       "      <td>-0.183453</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>wait till the war gets to Moscow  ....</td>\n",
       "      <td>-0.183453</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12155...</td>\n",
       "      <td>Russians hate Britain\\nAnd what they particula...</td>\n",
       "      <td>-0.183453</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://www.dailymail.co.uk/news/article-12155...   \n",
       "1  https://www.dailymail.co.uk/news/article-12155...   \n",
       "2  https://www.dailymail.co.uk/news/article-12155...   \n",
       "3  https://www.dailymail.co.uk/news/article-12155...   \n",
       "4  https://www.dailymail.co.uk/news/article-12155...   \n",
       "\n",
       "                                             comment  Sentiment  Polarity  \n",
       "0  Russians don't appear to understand that peopl...  -0.183453  Negative  \n",
       "1  The Russians dont like it up em do they? They ...  -0.183453  Negative  \n",
       "2                         well, russians wanted war.  -0.183453  Negative  \n",
       "3             wait till the war gets to Moscow  ....  -0.183453  Negative  \n",
       "4  Russians hate Britain\\nAnd what they particula...  -0.183453  Negative  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_parquet(\"dailyMailSentimentComment.parquet.snappy\", engine=\"fastparquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d7a18bc08bf6b314cad8b0dd8f53415ad78d1015cc806d14e4873c235fb4e191"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
